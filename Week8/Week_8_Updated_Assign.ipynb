{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping for Fun and Profit\n",
    "<img align=\"right\" style=\"padding-right:10px;\" src=\"figures_8/Hanshintigerslogo.png\" width=200><br>\n",
    "Collecting sports statistics is almost the \"Hello World\" of web scraping projects. Let's see if we can make it a little more interesting. \n",
    "\n",
    "**(Pointless backstory)**\n",
    "\n",
    "My wife is from Japan and over the years I've learned that the Japanese people love baseball as much as, or possibly even more than, Americans.  We've gone to see the local pro team, the Hanshin Tigers (Japanese: 阪神タイガース), a couple of times when visiting family and I've always wondered how Japanese players compare to American. In this assignment we will answer part of that question by comparing batting statistics for teams in Japan's Central League to teams in the US National League West.\n",
    "\n",
    "## Moneyball meet Sabermetrics\n",
    "\n",
    "The 2011 movie Moneyball () shows how Oakland A's general manager, Billy Beane, used statistics to build a low-cost winning team in 2002. The use of statistical analysis to evaluate player and team performance is called **sabermetrics** and can trace its lineage to Earnshaw Cook's 1964 book, \"Percentage Baseball\" (Wikipedia)\n",
    "\n",
    "We will be using a calculation from sabermetrics called **Base Runs** to evaluate team batting performance. Base runs uses several of the \"on base\" statistics for players or entire teams to estimate an offensive potential. The base runs calculation will be discussed in more detail below.\n",
    "\n",
    "**_Your job:_** create a \"base runs\" column and calculate base runs for each team for each year statistics are available and then do comparative analysis and visualization to determine Japanese vs. American baseball. \n",
    "\n",
    "***\n",
    "\n",
    "Moneyball: https://www.imdb.com/title/tt1210166/, https://en.wikipedia.org/wiki/Moneyball_(film)\n",
    "Sabermetrics: https://en.wikipedia.org/wiki/Sabermetrics\n",
    "SABR (Society for American Baseball Research) website: https://sabr.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "We will be using https://www.baseball-reference.com/ to gather our statistics. Their data is very well organized and the HTML is well-labeled and easy to navigate.\n",
    "\n",
    "\n",
    "### Japan Data\n",
    "\n",
    "**Japan Central League:** https://www.baseball-reference.com/register/league.cgi?code=JPCL&class=Fgn\n",
    "\n",
    "The Japan Central League is composed of 6 teams, **Chunichi Dragons, Hanshin Tigers, Hiroshima Carp, Yakult Swallows, Yokohama Bay Stars, Yomiuri Giants** (actually, some years had more teams), with data stretching back to 1950 organized into a table of links for teams for each year.\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/Japan_Central_League.png\" width=800><br>\n",
    "\n",
    "It should be a relatively easy task to scrape a list of links for each year (hint: think \"dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batting Stats\n",
    "\n",
    "Clicking a year link will take you to tables of league statistics for that year. To keep things simple, we will only scrape the second table -- **\"League Batting\"**.\n",
    "\n",
    "<img style=\"padding-right:10px;\" src=\"figures_8/2019_Japan_Central_Batting.png\" width=800><br>\n",
    "<br><br>\n",
    "Collect each team's statistics from the table and ignore the League Totals at the bottom of the table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Data\n",
    "\n",
    "The US National League West is composed of six teams: **Arizona Diamondbacks, Colorado Rockies, Los Angeles Dodgers , San Diego Padres, San Francisco Giants.** \n",
    "\n",
    "1. It is considerably less straightforward to get team stats for US teams. The best place I found to get links for all six teams is at the bottom of the main page in the \"Full Site Menu\" as seen in the picture below.\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/MLB_Stats.png\" width=200><br>\n",
    "\n",
    "2. Following one of the team links will take you to a team page. Underneath the main table on that page is a link to \"Batting\" under \"Year-by-year Stats\".\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/Colorado_Rockies_Team_History.png\" width=400><br>\n",
    "\n",
    "Following that link will take you to the page with batting statistics organized by year:\n",
    "\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures_8/Colorado_Rockies_Team_Yearly_Batting_Stats.png\" width=400><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Runs\n",
    "\n",
    "After you have collected all the data for all the teams and all the years, it is time to create the **base runs** column. According to http://tangotiger.net/wiki_archive/Base_Runs.html (linked from the SABR site), the formula to calculate base runs is:\n",
    "\n",
    "`A*B/(B + C) + D`\n",
    "\n",
    "Where:\n",
    "\n",
    "```\n",
    "A = H + BB - HR\n",
    "B = (1.4*SLG - .6*H - 3*HR + .1*BB)*1.02\n",
    "C = AB - H\n",
    "D = HR\n",
    "```\n",
    "\n",
    "<img style=\"padding-right:10px;\" src=\"figures_8/Colorado_Rockies_Detail.png\" width=800><br>\n",
    "\n",
    "*Note: There is a discrepancy between labeling of columns at Baseball-Reference and the Tangotiger formula. I've adjusted the formula to match Baseball-Reference.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the information above, for 2019:\n",
    "\n",
    "A = 1502 + 489 - 224 **= 1,767**<br>\n",
    "B = (1.4 * .456 - .6 * 1502 - .1 * 489) * 1.02 **= -968.450832**<br>\n",
    "C = 5660 - 1502 **= 4158**<br>\n",
    "D = **224**<br>\n",
    "\n",
    "A*B/(B + C) + D = 1,767 * -968.450832 / (-968.450832 + 4158) + 224\n",
    "\n",
    "= -312.518652013\n",
    "\n",
    "***\n",
    "\n",
    "Unfortunately, one of the weaknesses of base runs is that the answer can come out negative -- clearly a team cannot score **negative** runs in a season so you will have to decide how to deal with this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Word About HTML and Nested Tags\n",
    "\n",
    "A couple of decades ago, the US government finished a project that defined in excruciating detail how government documents would be formatted. More accurately, it defined the language used to create the formatting. This language is called **SGML** - Standard Generalized Markup Language. SGML is actually a language that defines rules for creating markup languages and it is the basis for HTML, XML, BPML, CML, and hundreds of others. \n",
    "\n",
    "SGML specifies that markup tags can be nested within each other, which has proven problematic for both HTML designers and parsers alike. This nesting forms a barrier to HTML parsing for many pages that we will want to scrape, including the Baseball-Reference page.\n",
    "\n",
    "<img style=\"padding-right:10px;\" src=\"figures_8/nested.png\" width=1000><br>\n",
    "\n",
    "***\n",
    "\n",
    "### Helpful Hints\n",
    "\n",
    "This assignment consists of 3 major sections:<br>\n",
    "1. Gather links to pages containing data by scraping tables.\n",
    "2. Scrape data from HTML tables into Pandas tables.\n",
    "3. Calculate new statistic and create visualizations.\n",
    "\n",
    "In these sports pages, tables are buried under several levels of nested \\<div> tags. Let's grab data off the hockey page to demonstrate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gazpacho import get, Soup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = f'COL'\n",
    "year = f'2016'\n",
    "base = f'https://www.hockey-reference.com'\n",
    "page = f'/teams/{state}/{year}.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'{base}{page}'\n",
    "html = get(url)\n",
    "soup = Soup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = soup.find('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the top-level \\<div> and everything inside. Now we can look for the table. NOTE: the `find()` method returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(div[0].find('table')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>AvAge</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OL</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PTS%</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>...</th>\n",
       "      <th>PPOA</th>\n",
       "      <th>PK%</th>\n",
       "      <th>SH</th>\n",
       "      <th>SHA</th>\n",
       "      <th>S</th>\n",
       "      <th>S%</th>\n",
       "      <th>SA</th>\n",
       "      <th>SV%</th>\n",
       "      <th>PDO</th>\n",
       "      <th>SO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Colorado Avalanche</td>\n",
       "      <td>28.3</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0.500</td>\n",
       "      <td>212</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>258</td>\n",
       "      <td>80.23</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2348</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2649</td>\n",
       "      <td>0.909</td>\n",
       "      <td>100.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>League Average</td>\n",
       "      <td>28.0</td>\n",
       "      <td>82</td>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>0.556</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>81.34</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2438</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2438</td>\n",
       "      <td>0.910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Team  AvAge  GP   W   L  OL  PTS   PTS%   GF   GA  ...  PPOA  \\\n",
       "0  Colorado Avalanche   28.3  82  39  39   4   82  0.500  212  240  ...   258   \n",
       "1      League Average   28.0  82  41  32   9   91  0.556  219  219  ...   255   \n",
       "\n",
       "     PK%  SH  SHA     S   S%    SA    SV%    PDO  SO  \n",
       "0  80.23   7    9  2348  9.0  2649  0.909  100.5   5  \n",
       "1  81.34   6    6  2438  9.0  2438  0.910    NaN   5  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we were scraping the actual data so I converted it to a DataFrame. In the case of harvesting links, you probably want to use the raw list that the `find()` gives you and pull the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable\n",
    "\n",
    "Your job is to present a comparative analysis between Japanese Central League baseball teams and American National League West teams using the **\"base run\"** statistic calculated from data scraped from the Baseball-Reference website. This analysis should contain tables and visualizations to support an ultimate answer to which country's baseball teams are stronger. You are free to use any combination of requests, beautifulsoup, gazpacho, scrapy, etc. that you feel comfortable with to gather the data and any visualization library you want.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> As noted in the Zoom session this evening, we discovered that the American league batting tables are not easily parsed.  Here is a solution for working with these tables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for Colorado Rockies Year-by-Year Batting\n",
    "url_mlb=\"https://www.baseball-reference.com/teams/COL/batteam.shtml\"\n",
    "\n",
    "html = get(url_mlb)\n",
    "soup = Soup(html)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the outter level 'div'\n",
    "div = soup.find('div',{'id':'content'},mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the html string to represent what we want it to look like\n",
    "table = str(div[0].find('table', {'id':'yby_team_bat'})) + str(div[0].find('tbody')) + '</table>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into a pd dataframe\n",
    "df = pd.read_html(table)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Notice the odd column name in the middle of the dataframe header. We might want to clean this up.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>Info!</strong> For those having trouble with the Japanese stats, use the functions below. Should also work for American teams.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from https://github.com/BenKite/baseball_data/blob/master/baseballReferenceScrape.py\n",
    "##\n",
    "## This function simply takes a url and provides the ids\n",
    "## from the html tables that the code provided here can access.\n",
    "## Using findTables is great for determining options for the\n",
    "## pullTable function for the tableID argument.\n",
    "\n",
    "def findTables(url):\n",
    "    res = requests.get(url)\n",
    "    ## The next two lines get around the issue with comments breaking the parsing.\n",
    "    comm = re.compile(\"<!--|-->\")\n",
    "    soup = bs4.BeautifulSoup(comm.sub(\"\", res.text), 'lxml')\n",
    "    divs = soup.findAll('div', id = \"content\")\n",
    "    divs = divs[0].findAll(\"div\", id=re.compile(\"^all\"))\n",
    "    ids = []\n",
    "    for div in divs:\n",
    "        searchme = str(div.findAll(\"table\"))\n",
    "        x = searchme[searchme.find(\"id=\") + 3: searchme.find(\">\")]\n",
    "        x = x.replace(\"\\\"\", \"\")\n",
    "        if len(x) > 0:\n",
    "            ids.append(x)\n",
    "    return(ids)\n",
    "\n",
    "## For example:\n",
    "## findTables(\"http://www.baseball-reference.com/teams/KCR/2016.shtml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_batting',\n",
       " 'team_pitching',\n",
       " 'appearances',\n",
       " 'coaches',\n",
       " 'standard_fielding',\n",
       " 'players_value_batting',\n",
       " 'players_value_pitching']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findTables(\"http://www.baseball-reference.com/teams/COL/2016.shtml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulls a single table from a url provided by the user.\n",
    "## The desired table should be specified by tableID.\n",
    "## This function is used in all functions that do more complicated pulls.\n",
    "\n",
    "def pullTable(url, tableID):\n",
    "    res = requests.get(url)\n",
    "    ## Work around comments\n",
    "    comm = re.compile(\"<!--|-->\")\n",
    "    soup = bs4.BeautifulSoup(comm.sub(\"\", res.text), 'lxml')\n",
    "    tables = soup.findAll('table', id = tableID)\n",
    "    data_rows = tables[0].findAll('tr')\n",
    "    data_header = tables[0].findAll('thead')\n",
    "    data_header = data_header[0].findAll(\"tr\")\n",
    "    data_header = data_header[0].findAll(\"th\")\n",
    "    game_data = [[td.getText() for td in data_rows[i].findAll(['th','td'])]\n",
    "        for i in range(len(data_rows))\n",
    "        ]\n",
    "    data = pd.DataFrame(game_data)\n",
    "    header = []\n",
    "    for i in range(len(data.columns)):\n",
    "        header.append(data_header[i].getText())\n",
    "    data.columns = header\n",
    "    data = data.loc[data[header[0]] != header[0]]\n",
    "    data = data.reset_index(drop = True)\n",
    "    return(data)\n",
    "\n",
    "## For example:\n",
    "## url = \"http://www.baseball-reference.com/teams/KCR/2016.shtml\"\n",
    "## pullTable(url, \"team_batting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWestTeams = ['COL','ARI','LAD','SDP','SFG'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH COL https://www.baseball-reference.com/teams/COL/batteam.shtml\n",
      "Non-Match ARI\n",
      "Non-Match LAD\n",
      "Non-Match SDP\n",
      "Non-Match SFG\n"
     ]
    }
   ],
   "source": [
    "#testing the creating of URL and match of Teams from a list\n",
    "\n",
    "for team in NLWestTeams:\n",
    "    url_base = \"https://www.baseball-reference.com/teams/\"\n",
    "    addTeam = team\n",
    "    url_end = \"/batteam.shtml\" \n",
    "    url = url_base + addTeam + url_end\n",
    "    if url == url_mlb:\n",
    "        print('MATCH', team, url)\n",
    "    else:\n",
    "        print('Non-Match',team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing grabbing data from the site and adding it to a list then a DataFram\n",
    "team = 'COL'                                                      #Testing with the Colorado Rockies\n",
    "LoopDF = pd.DataFrame()\n",
    "LoopList = []\n",
    "for year in range(1999,2020):                                     #creating a list of years to loop through\n",
    "    url_base = \"https://www.baseball-reference.com/teams/\"        #breaking the url down into parts so we can loop through teams later\n",
    "    addTeam = team                                                \n",
    "    url_end = '.shtml'                                            #saving the ending \n",
    "    url = url_base + addTeam + \"/\" + str(year) + url_end          #concatinating the url back together\n",
    "    data = pullTable(url, \"team_batting\")                         #pull team batting table data from the url\n",
    "    data['Year'] = year                                           #adding year and team to identify after everthing is combined \n",
    "    data['Team'] = team\n",
    "    LoopList.append(data)                                         #appending the data we just collected to a list outside the loop\n",
    "LoopDF = LoopDF.append(LoopList, ignore_index = True)                      #appending the list that was created from the loop into a DataFrame\n",
    "\n",
    "# Looks like everything Worked. Lets try setting it up to pull Year-by-Year Team Batting from\n",
    "# https://www.baseball-reference.com/teams/COL/batteam.shtml\n",
    "# https://www.baseball-reference.com/teams/TEAM/batteam.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest = pd.DataFrame()                                         # Create an empty dataframe\n",
    "teambatting = []                                                # Create a empty list will use to append data from the For loop\n",
    "for team in NLWestTeams:                                        # Loop through each team in the NLwest\n",
    "    url_base = 'https://www.baseball-reference.com/teams/'      # Breaking up URL so we can change the URL depending on which team we are pulling\n",
    "    addTeam = team                                              \n",
    "    url_end = '/batteam.shtml'\n",
    "    url = url_base + addTeam + url_end                          # Pulling the URL together to pull from that page\n",
    "    data = pullTable(url, \"yby_team_bat\")                       # Using PullTable to get the year by year table from the URL\n",
    "    data['team'] = team                                         # adding team name to the list for ablity to ID easier in the DataFrame\n",
    "    teambatting.append(data)                                    # Appending everything to teambatting\n",
    "    \n",
    "NLWest = NLWest.append(teambatting, ignore_index = True)        # Turning the Teambatting into a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to test and pull the Japan team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lg_history']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findTables('https://www.baseball-reference.com/register/league.cgi?code=JPCL&class=Fgn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url_jpn = 'https://www.baseball-reference.com/register/league.cgi?code=JPCL&class=Fgn'\n",
    "resp = requests.get(url_jpn)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "len(soup.find_all('a'))\n",
    "len(soup.find_all('table'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/register/team.cgi?id=440abdcc',\n",
       " '/register/team.cgi?id=5b8c0aae',\n",
       " '/register/team.cgi?id=b758241e',\n",
       " '/register/team.cgi?id=7dcd3bed',\n",
       " '/register/team.cgi?id=104f07f5',\n",
       " '/register/team.cgi?id=8a52b102',\n",
       " '/register/team.cgi?id=6cd77290',\n",
       " '/register/team.cgi?id=81a0f195',\n",
       " '/register/team.cgi?id=132c15ba',\n",
       " '/register/team.cgi?id=b5237ebe',\n",
       " '/register/team.cgi?id=232bcf74',\n",
       " '/register/team.cgi?id=fe01330f',\n",
       " '/register/team.cgi?id=16498b57',\n",
       " '/register/team.cgi?id=2a90bed3',\n",
       " '/register/team.cgi?id=707590b1',\n",
       " '/register/team.cgi?id=5e91a021',\n",
       " '/register/team.cgi?id=f995e1f8',\n",
       " '/register/team.cgi?id=9c29067e',\n",
       " '/register/team.cgi?id=649851aa',\n",
       " '/register/team.cgi?id=84a8c055',\n",
       " '/register/team.cgi?id=56354bdd',\n",
       " '/register/team.cgi?id=5d636e2b',\n",
       " '/register/team.cgi?id=f2dc9b63',\n",
       " '/register/team.cgi?id=b6c7f7c1',\n",
       " '/register/team.cgi?id=25346c0b',\n",
       " '/register/team.cgi?id=e4bbc1de',\n",
       " '/register/team.cgi?id=af9de917',\n",
       " '/register/team.cgi?id=d09a2719',\n",
       " '/register/team.cgi?id=f789dc4b',\n",
       " '/register/team.cgi?id=0569261f',\n",
       " '/register/team.cgi?id=bcaec53c',\n",
       " '/register/team.cgi?id=f850467b',\n",
       " '/register/team.cgi?id=c73c8956',\n",
       " '/register/team.cgi?id=3e372e86',\n",
       " '/register/team.cgi?id=3f077d78',\n",
       " '/register/team.cgi?id=fe7c703a',\n",
       " '/register/team.cgi?id=51ff3999',\n",
       " '/register/team.cgi?id=4110b52f',\n",
       " '/register/team.cgi?id=1e747553',\n",
       " '/register/team.cgi?id=29ab8e1d',\n",
       " '/register/team.cgi?id=b3006104',\n",
       " '/register/team.cgi?id=98e67f4c',\n",
       " '/register/team.cgi?id=1219605e',\n",
       " '/register/team.cgi?id=e5093293',\n",
       " '/register/team.cgi?id=8da1373a',\n",
       " '/register/team.cgi?id=c3e77927',\n",
       " '/register/team.cgi?id=669bcc15',\n",
       " '/register/team.cgi?id=a0f0efcf',\n",
       " '/register/team.cgi?id=a0251f11',\n",
       " '/register/team.cgi?id=6aa33e49',\n",
       " '/register/team.cgi?id=07f0dbe3',\n",
       " '/register/team.cgi?id=c7f6c07f',\n",
       " '/register/team.cgi?id=ec0ae973',\n",
       " '/register/team.cgi?id=a05137a5',\n",
       " '/register/team.cgi?id=e35a8181',\n",
       " '/register/team.cgi?id=b2299068',\n",
       " '/register/team.cgi?id=90cc9a30',\n",
       " '/register/team.cgi?id=87114b02',\n",
       " '/register/team.cgi?id=225a7798',\n",
       " '/register/team.cgi?id=df16668c',\n",
       " '/register/team.cgi?id=e28eab06',\n",
       " '/register/team.cgi?id=a3e37bfa',\n",
       " '/register/team.cgi?id=71cc744d',\n",
       " '/register/team.cgi?id=4e8dbe99',\n",
       " '/register/team.cgi?id=d65baf75',\n",
       " '/register/team.cgi?id=7a19c0ab',\n",
       " '/register/team.cgi?id=1aaee33e',\n",
       " '/register/team.cgi?id=ed4c7720',\n",
       " '/register/team.cgi?id=e8a8b780',\n",
       " '/register/team.cgi?id=3103517b']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpn_urls = []    \n",
    "for h in soup.find_all('td'):\n",
    "    try:\n",
    "        jpn_urls.append(h.find('a').attrs['href'])\n",
    "    except:\n",
    "        pass\n",
    "jpn_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.baseball-reference.com/register/team.cgi?id=440abdcc',\n",
       " 'https://www.baseball-reference.com/register/team.cgi?id=5b8c0aae']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpn_base = 'https://www.baseball-reference.com'\n",
    "team_urls = [jpn_base + x for x in jpn_urls]       # Creating a list of all of the URLs i need to grab data from\n",
    "test_url = team_urls[:2]                           # Creating a subset to use for testing\n",
    "test_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009', 'Chunichi Dragons', '']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working on pulling the team name and year from to append to the stats list\n",
    "nameYear = []\n",
    "url_jpn = 'https://www.baseball-reference.com/register/team.cgi?id=232bcf74'\n",
    "resp = requests.get(url_jpn)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "for h in soup.find_all('div',{'id':'meta'}):      # Pulling all divs where id = 'meta'\n",
    "    for x in h.find_all('span'):                  # looping through the spans from the meta div and \n",
    "        nameYear.append(x.text)                   # appending the text to NameYear.\n",
    "    \n",
    "\n",
    "# print(teamname)\n",
    "nameYear                                          # There is a blank in the list. need to append [:2] when putting the list together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of column names to use in creating a dictionary with zip\n",
    "jpn_col = ['Rk','Name','Age','G','PA','AB','R','H','2B','3B','HR','RBI','SB','CS','BB','SO','BA','OBP','SLG','OPS','TB','GDP','HBP','SH','SF','IBB','Notes','Year','TeamName']\n",
    "jpnlist = []\n",
    "for x in team_urls:                                       # Loop through all of the URLS\n",
    "    nameYear = []                                         # First get the Name and Year of the team we are currently scraping\n",
    "    resp = requests.get(x)                                # Request the team url\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')               # Request text from the URL\n",
    "    for h in soup.find_all('div',{'id':'meta'}):          # Loop through all div's with id = meta\n",
    "        for i in h.find_all('span'):                      # Loop through all the spans within the divs that were found\n",
    "            nameYear.append(i.text)                       # append the text from the spans to nameYear\n",
    "    pull = pullTable(x,'team_batting')                    # use pullTable to get the team batting table\n",
    "    last = pull.last_valid_index()                        # pullTable pulls all players stats but we want the team totals which are in the past row so we need to find the last index\n",
    "    last = pull.iloc[last]                                # use iloc to save the last index row\n",
    "    last = last.append(pd.Series(nameYear[:2]))           # append the first to  values (year, teamName) to the end of last\n",
    "    jpnlist.append(dict(zip(jpn_col,last)))               # zip header(Key) and last(Value) together into a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data Cleaning process is almost over. Just get the JPNlist into a dataframe and convert each column to the correct type and make a copy of each Dataframe for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpndf = pd.DataFrame.from_dict(jpnlist)\n",
    "jpndf_copy = jpndf.copy()\n",
    "jpndfTeam = jpndf['TeamName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpndf.drop(['Name','Notes','TeamName'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpndf = jpndf.apply(lambda col:pd.to_numeric(col, errors='coerce'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpndf['TeamName'] = jpndfTeam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWestCopy = NLWest.copy                           #Making a copy of the dataframe just in case seomthing goes wrong\n",
    "NLSave = NLWest[['team','Lg']]                     # Copying team and Lg to a different dataframe while i convert \n",
    "                                                   # everyting to a float or int and we dont need the League info bc every team is in the NLWest\n",
    "NLWest.drop(['team','Lg'], axis=1, inplace=True)   # dropping columns in prep for the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest = NLWest.apply(lambda col:pd.to_numeric(col, errors='coerce'))  \n",
    "# converting data types objects to float / ints \n",
    "# https://stackoverflow.com/questions/28277137/how-to-convert-datatypeobject-to-float64-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest['Team'] = NLSave['team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaseRunCal(DF):\n",
    "    A = DF['H'] + DF['BB'] - DF['HR']\n",
    "    B =((1.4*DF['SLG']) - (.6*DF['H']) - (3*DF['HR']) + (.1*DF['BB'])) * 1.02\n",
    "    C = DF['AB'] - DF['H']\n",
    "    D = DF['HR']\n",
    "    DF = A * B / (B + C) + D\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest['BaseRuns'] = BaseRunCal(NLWest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpndf['BaseRuns'] = BaseRunCal(jpndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWBaseRunsMin = 1167.44\n",
    "NLWBaseRunsMax = 215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest['BaseRunsShift'] = NLWest['BaseRuns'] + NLWBaseRunsMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "\n",
    "NLMinMax = NLWest[['BaseRuns','BaseRunsShift']]\n",
    "NLMinMax[['BaseRuns','BaseRunsShift']] = scaler.fit_transform(NLMinMax[['BaseRuns','BaseRunsShift']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3498: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc._setitem_with_indexer((slice(None), indexer), value)\n",
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3469: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    }
   ],
   "source": [
    "jpndf.min()\n",
    "jpndf['BaseRunsShift'] = jpndf['BaseRuns'] + NLWBaseRunsMin\n",
    "jpnBRdf =jpndf[['BaseRuns','BaseRunsShift']]\n",
    "jpnBRdf[['BaseRuns','BaseRunsShift']] = scaler.fit_transform(jpnBRdf[['BaseRuns','BaseRunsShift']])\n",
    "jpndf['BRScaled'] = jpnBRdf['BaseRuns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinmurray/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "NLMinMax.rename(columns={\"BaseRuns\": \"BRScaled\", \"BaseRunsShift\": \"BRShiftScaled\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLWest['BRScaled'] = NLMinMax['BRScaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>Finish</th>\n",
       "      <th>R/G</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>E</th>\n",
       "      <th>DP</th>\n",
       "      <th>Fld%</th>\n",
       "      <th>BatAge</th>\n",
       "      <th>BaseRuns</th>\n",
       "      <th>BaseRunsShift</th>\n",
       "      <th>BRScaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">ARI</td>\n",
       "      <td>1998</td>\n",
       "      <td>65</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>4.10</td>\n",
       "      <td>162</td>\n",
       "      <td>6116</td>\n",
       "      <td>5491</td>\n",
       "      <td>665</td>\n",
       "      <td>1353</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.707</td>\n",
       "      <td>100</td>\n",
       "      <td>125</td>\n",
       "      <td>0.984</td>\n",
       "      <td>27.8</td>\n",
       "      <td>-581.307411</td>\n",
       "      <td>586.132589</td>\n",
       "      <td>0.616547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>5.60</td>\n",
       "      <td>162</td>\n",
       "      <td>6415</td>\n",
       "      <td>5658</td>\n",
       "      <td>908</td>\n",
       "      <td>1566</td>\n",
       "      <td>289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.805</td>\n",
       "      <td>104</td>\n",
       "      <td>132</td>\n",
       "      <td>0.983</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-976.446581</td>\n",
       "      <td>190.993419</td>\n",
       "      <td>0.200902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "      <td>4.89</td>\n",
       "      <td>162</td>\n",
       "      <td>6241</td>\n",
       "      <td>5527</td>\n",
       "      <td>792</td>\n",
       "      <td>1466</td>\n",
       "      <td>282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.763</td>\n",
       "      <td>107</td>\n",
       "      <td>138</td>\n",
       "      <td>0.982</td>\n",
       "      <td>30.8</td>\n",
       "      <td>-768.916820</td>\n",
       "      <td>398.523180</td>\n",
       "      <td>0.419202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2001</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>5.05</td>\n",
       "      <td>162</td>\n",
       "      <td>6349</td>\n",
       "      <td>5595</td>\n",
       "      <td>818</td>\n",
       "      <td>1494</td>\n",
       "      <td>284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.783</td>\n",
       "      <td>84</td>\n",
       "      <td>148</td>\n",
       "      <td>0.986</td>\n",
       "      <td>31.9</td>\n",
       "      <td>-861.192251</td>\n",
       "      <td>306.247749</td>\n",
       "      <td>0.322138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2002</td>\n",
       "      <td>98</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5.06</td>\n",
       "      <td>162</td>\n",
       "      <td>6318</td>\n",
       "      <td>5508</td>\n",
       "      <td>819</td>\n",
       "      <td>1471</td>\n",
       "      <td>283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.769</td>\n",
       "      <td>89</td>\n",
       "      <td>116</td>\n",
       "      <td>0.985</td>\n",
       "      <td>31.7</td>\n",
       "      <td>-802.235009</td>\n",
       "      <td>365.204991</td>\n",
       "      <td>0.384154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">SFG</td>\n",
       "      <td>2015</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>4.30</td>\n",
       "      <td>162</td>\n",
       "      <td>6153</td>\n",
       "      <td>5565</td>\n",
       "      <td>696</td>\n",
       "      <td>1486</td>\n",
       "      <td>288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.732</td>\n",
       "      <td>78</td>\n",
       "      <td>145</td>\n",
       "      <td>0.987</td>\n",
       "      <td>28.9</td>\n",
       "      <td>-688.846157</td>\n",
       "      <td>478.593843</td>\n",
       "      <td>0.503428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>87</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>4.41</td>\n",
       "      <td>162</td>\n",
       "      <td>6271</td>\n",
       "      <td>5565</td>\n",
       "      <td>715</td>\n",
       "      <td>1437</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.728</td>\n",
       "      <td>72</td>\n",
       "      <td>136</td>\n",
       "      <td>0.988</td>\n",
       "      <td>29.1</td>\n",
       "      <td>-656.771862</td>\n",
       "      <td>510.668138</td>\n",
       "      <td>0.537166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>3.94</td>\n",
       "      <td>162</td>\n",
       "      <td>6137</td>\n",
       "      <td>5551</td>\n",
       "      <td>639</td>\n",
       "      <td>1382</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.689</td>\n",
       "      <td>87</td>\n",
       "      <td>127</td>\n",
       "      <td>0.985</td>\n",
       "      <td>29.5</td>\n",
       "      <td>-558.899642</td>\n",
       "      <td>608.540358</td>\n",
       "      <td>0.640118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>162</td>\n",
       "      <td>6113</td>\n",
       "      <td>5541</td>\n",
       "      <td>603</td>\n",
       "      <td>1324</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.667</td>\n",
       "      <td>97</td>\n",
       "      <td>160</td>\n",
       "      <td>0.984</td>\n",
       "      <td>29.8</td>\n",
       "      <td>-497.129516</td>\n",
       "      <td>670.310484</td>\n",
       "      <td>0.705094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019</td>\n",
       "      <td>77</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>4.19</td>\n",
       "      <td>162</td>\n",
       "      <td>6170</td>\n",
       "      <td>5579</td>\n",
       "      <td>678</td>\n",
       "      <td>1332</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.694</td>\n",
       "      <td>90</td>\n",
       "      <td>142</td>\n",
       "      <td>0.985</td>\n",
       "      <td>29.9</td>\n",
       "      <td>-538.298153</td>\n",
       "      <td>629.141847</td>\n",
       "      <td>0.661788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             W   L  Finish   R/G    G    PA    AB    R     H   2B  ...    OBP  \\\n",
       "Team Year                                                          ...          \n",
       "ARI  1998   65  97       5  4.10  162  6116  5491  665  1353  235  ...  0.314   \n",
       "     1999  100  62       1  5.60  162  6415  5658  908  1566  289  ...  0.347   \n",
       "     2000   85  77       3  4.89  162  6241  5527  792  1466  282  ...  0.333   \n",
       "     2001   92  70       1  5.05  162  6349  5595  818  1494  284  ...  0.341   \n",
       "     2002   98  64       1  5.06  162  6318  5508  819  1471  283  ...  0.346   \n",
       "...        ...  ..     ...   ...  ...   ...   ...  ...   ...  ...  ...    ...   \n",
       "SFG  2015   84  78       2  4.30  162  6153  5565  696  1486  288  ...  0.326   \n",
       "     2016   87  75       2  4.41  162  6271  5565  715  1437  280  ...  0.329   \n",
       "     2017   64  98       5  3.94  162  6137  5551  639  1382  290  ...  0.309   \n",
       "     2018   73  89       4  3.72  162  6113  5541  603  1324  255  ...  0.300   \n",
       "     2019   77  85       3  4.19  162  6170  5579  678  1332  300  ...  0.302   \n",
       "\n",
       "             SLG    OPS    E   DP   Fld%  BatAge    BaseRuns  BaseRunsShift  \\\n",
       "Team Year                                                                     \n",
       "ARI  1998  0.393  0.707  100  125  0.984    27.8 -581.307411     586.132589   \n",
       "     1999  0.459  0.805  104  132  0.983    30.0 -976.446581     190.993419   \n",
       "     2000  0.429  0.763  107  138  0.982    30.8 -768.916820     398.523180   \n",
       "     2001  0.442  0.783   84  148  0.986    31.9 -861.192251     306.247749   \n",
       "     2002  0.423  0.769   89  116  0.985    31.7 -802.235009     365.204991   \n",
       "...          ...    ...  ...  ...    ...     ...         ...            ...   \n",
       "SFG  2015  0.406  0.732   78  145  0.987    28.9 -688.846157     478.593843   \n",
       "     2016  0.398  0.728   72  136  0.988    29.1 -656.771862     510.668138   \n",
       "     2017  0.380  0.689   87  127  0.985    29.5 -558.899642     608.540358   \n",
       "     2018  0.368  0.667   97  160  0.984    29.8 -497.129516     670.310484   \n",
       "     2019  0.392  0.694   90  142  0.985    29.9 -538.298153     629.141847   \n",
       "\n",
       "           BRScaled  \n",
       "Team Year            \n",
       "ARI  1998  0.616547  \n",
       "     1999  0.200902  \n",
       "     2000  0.419202  \n",
       "     2001  0.322138  \n",
       "     2002  0.384154  \n",
       "...             ...  \n",
       "SFG  2015  0.503428  \n",
       "     2016  0.537166  \n",
       "     2017  0.640118  \n",
       "     2018  0.705094  \n",
       "     2019  0.661788  \n",
       "\n",
       "[373 rows x 28 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLWest.groupby(['Team', 'Year']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = NLWest.groupby(['Year','Team']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Team\n",
       "1883  SFG     0.933181\n",
       "1884  LAD     1.000000\n",
       "      SFG     0.863982\n",
       "1885  LAD     0.920623\n",
       "      SFG     0.829520\n",
       "                ...   \n",
       "2019  ARI     0.463084\n",
       "      COL     0.354269\n",
       "      LAD     0.268483\n",
       "      SDP     0.605445\n",
       "      SFG     0.661788\n",
       "Name: BRScaled, Length: 373, dtype: float64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stats['BRScaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
